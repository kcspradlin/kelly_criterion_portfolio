{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eded6a3e",
   "metadata": {},
   "source": [
    "This notebook will demonstrate how to use Python and some of its modules to estimate parameters of a multi-variate normal distribution for a randomly-generated set of data.  It will use the maximum likelihood estimation (MLE) approach to find the parameters.\n",
    "\n",
    "Created on August 29-30 and September 3-5, 2022 by Kevin Spradlin, Jr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7a919",
   "metadata": {},
   "source": [
    "First, import some Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac78c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80edb14e",
   "metadata": {},
   "source": [
    "Next, create a set of random multi-variate normal variates using the scipy.stats ***multivariate_normal*** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9dd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_matrix_pos_semidef(test_matrix: np.array) -> typing.Dict:\n",
    "    \"\"\"\n",
    "    This function will test the array test_matrix to see if it's positive \n",
    "     semi-definite, using this definition:\n",
    "\n",
    "     \"A positive semidefinite matrix is a Hermitian matrix all of whose eigenvalues are nonnegative.\"\n",
    "     https://mathworld.wolfram.com/HermitianMatrix.html\n",
    "\n",
    "     It will check if the matrix is square, Hermitian, and only has positive \n",
    "     eigenvalues.\n",
    "\n",
    "     The function will return a dictionary.  One key is 'pass_test', which\n",
    "      will be True if it's positive semi-definite and False if not.  The\n",
    "      other key is 'message' will will state why the matrix failed the test,\n",
    "      or will be blank it it passed the test.\n",
    "\n",
    "    Created on June 8, 2022\n",
    "    \"\"\"\n",
    "\n",
    "    pass_test: bool = False\n",
    "    message: str = ''\n",
    "\n",
    "\n",
    "    # check if the matrix is square\n",
    "    matrix_dimensions: List = list(test_matrix.shape)\n",
    "\n",
    "    if len(matrix_dimensions) != 2:\n",
    "        message = 'Matrix needs to have 2 dimensions'\n",
    "        return {'pass_test': pass_test, 'message': message}\n",
    "\n",
    "    if matrix_dimensions[0] != matrix_dimensions[1]:\n",
    "        message = 'Matrix needs to be square'\n",
    "        return {'pass_test': pass_test, 'message': message}\n",
    "\n",
    "\n",
    "    # check if the matrix is Hermitian\n",
    "    complex_conjugate: np.array = np.matrix.getH(test_matrix)\n",
    "\n",
    "    if not np.array_equal(test_matrix, complex_conjugate):\n",
    "        message = \"Matrix isn\\'t Hermitian - equal to complex conjugate of itself\"\n",
    "        return {'pass_test': pass_test, 'message': message}\n",
    "\n",
    "\n",
    "    # calculate the matrix's eigenvalues and check if any are negative\n",
    "    for current_eigenvalue in np.linalg.eigvals(test_matrix):\n",
    "        if current_eigenvalue < 0:\n",
    "            message = f\"Matrix has eigenvalue of {current_eigenvalue:6.4f}\"\n",
    "            break\n",
    "\n",
    "\n",
    "    if message:\n",
    "        return {'pass_test': pass_test, 'message': message}\n",
    "    else:\n",
    "        return {'pass_test': True, 'message': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d92258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the user define the means and covariance matrix of the multi-variate normal distribution\n",
    "mean_vector: np.ndarray = np.asarray([2.85, -3.65], dtype=np.float32)\n",
    "\n",
    "# this covariance matrix doesn't lead to the optimization function landing on a matrix\n",
    "#  that's not positive semi-definite.\n",
    "#cov_matrix: np.ndarray = np.asarray([[7.05, -3.15], [-3.15, 2.45]], dtype=np.float32)\n",
    "\n",
    "# this covariance matrix leads to the optimization function landing on a matrix that's\n",
    "#  not positive semi-definite.  that's where the 'trial_pos_semidef_matrix' function\n",
    "#  comes into play.\n",
    "cov_matrix: np.ndarray = np.asarray([[7.05, -3.65], [-3.65, 2.25]], dtype=np.float32)\n",
    "\n",
    "    \n",
    "# check that the matrix is positive semi-definite\n",
    "function_results: typing.Dict = is_matrix_pos_semidef(cov_matrix)\n",
    "\n",
    "if not function_results['pass_test']:\n",
    "    print(function_results['message'])\n",
    "\n",
    "\n",
    "# generate 10,000 random variates\n",
    "random_sample: np.ndarray = stats.multivariate_normal.rvs(mean=mean_vector, cov=cov_matrix, size=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4b68b",
   "metadata": {},
   "source": [
    "Before we use the MLE approach, let's calculate the basic statistics of the sample of random multi-variate normal variates.  They should show that the mean vector and standard deviations of the sample are close to the values you defined, since the parameters that maximize the likelihood function are the sample means and standard deviations.  The sample statistics should also show that the skewnesses and excess kurtosis (kurtoses ?) are close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4f18e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample means: [ 2.786  -3.6179]\n",
      "Sample variances: [7.021  2.2483]\n",
      "Sample skewnesses: [-0.0334  0.0129]\n",
      "Sample excess kurtosis: [-0.006  -0.0288]\n"
     ]
    }
   ],
   "source": [
    "results = stats.describe(random_sample)\n",
    "print(f\"Sample means: {np.array2string(results[2], precision=4):s}\")\n",
    "print(f\"Sample variances: {np.array2string(results[3], precision=4):s}\")\n",
    "print(f\"Sample skewnesses: {np.array2string(results[4], precision=4):s}\")\n",
    "print(f\"Sample excess kurtosis: {np.array2string(results[5], precision=4):s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf475b65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, we'll use the MLE approach.\n",
    "First define a function that calculates the log-likelihood function.  Then find the parameters that maximize the log-likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c5c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_lh_parameters_norm(parameters: np.ndarray, num_dimensions: int) -> typing.Dict:\n",
    "    \"\"\"\n",
    "    This function will convert the elements of the parameters array into a\n",
    "     mean vector and a covariance matrix.  It will return them as values\n",
    "     in a dictionary.\n",
    "    \n",
    "    Created on August 30 and September 5, 2022\n",
    "    \"\"\"\n",
    "\n",
    "    mean_vector: np.ndarray = parameters[0:num_dimensions]\n",
    "\n",
    "    cov_matrix: np.ndarray = np.zeros((num_dimensions, num_dimensions), dtype=np.float32)\n",
    "\n",
    "    addend: int = num_dimensions\n",
    "    for current_column in range(num_dimensions):\n",
    "        addend -= current_column\n",
    "        \n",
    "        for current_row1 in range(0, current_column):\n",
    "            cov_matrix[current_row1, current_column] = cov_matrix[current_column, current_row1]\n",
    "        \n",
    "        for current_row2 in range(current_column, num_dimensions):\n",
    "            cov_matrix[current_row2, current_column] = \\\n",
    "              parameters[current_row2 + current_column * num_dimensions + addend]\n",
    "    \n",
    "    \n",
    "    return {'mean_vector': mean_vector, 'covariance_matrix': cov_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d658b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_pos_semidef_matrix(test_matrix: np.array) -> typing.Dict:\n",
    "    \"\"\"\n",
    "    This function will take a matrix return a new matrix, based on the\n",
    "     eigendecomposition of the original matrix.  The original matrix's \n",
    "     eigenvalues and vectors will be calculated.  If any eigenvalues are\n",
    "     non-positive, then they will be set to be slightly positive.  The\n",
    "     new matrix will be calculated from the original matrix's eigenvectors,\n",
    "     any of the original eigenvalues that are positive, and the adjusted, \n",
    "     now-slightly positive eigenvalues.\n",
    "     \n",
    "    The new matrix will be positive semi-definite.\n",
    "    \n",
    "    Got information about eigendecomposition from this site:\n",
    "    https://mathworld.wolfram.com/EigenDecomposition.html\n",
    "    \n",
    "    Created on September 3, 2022\n",
    "    \"\"\"    \n",
    "    \n",
    "    message: str = ''\n",
    "    \n",
    "    \n",
    "    # first, make sure the matrix is symmetric\n",
    "    matrix_dimensions: List = list(test_matrix.shape)\n",
    "\n",
    "    if len(matrix_dimensions) != 2:\n",
    "        message = 'Matrix needs to have 2 dimensions'\n",
    "        return {'any_errors': True, 'message': message}\n",
    "\n",
    "    if matrix_dimensions[0] != matrix_dimensions[1]:\n",
    "        message = 'Matrix needs to be square'\n",
    "        return {'any_errors': True, 'message': message}\n",
    "\n",
    " \n",
    "    if not np.array_equal(test_matrix, test_matrix.T):\n",
    "        message = \"Matrix isn\\'t symmetric\"\n",
    "        return {'any_errors': True, 'message': message}\n",
    "   \n",
    "\n",
    "    # next, calculate the eigenvalues and eigenvectors of the matrix\n",
    "    matrix_p: np.ndarray = np.zeros((matrix_dimensions[0], matrix_dimensions[0]), dtype=np.float32)\n",
    "    matrix_d: np.ndarray = np.zeros((matrix_dimensions[0], matrix_dimensions[0]), dtype=np.float32)\n",
    "    \n",
    "    test_eigenvalues, test_eigenvectors = np.linalg.eig(test_matrix)\n",
    "\n",
    "    \n",
    "    for current_index, current_eigenvalue in enumerate(test_eigenvalues):\n",
    "        matrix_p[:,current_index] = test_eigenvectors[:,current_index]\n",
    "       \n",
    "        if current_eigenvalue >= 0.0:\n",
    "            matrix_d[current_index, current_index] = current_eigenvalue\n",
    "        else:\n",
    "            matrix_d[current_index, current_index] = np.random.rand() / 10.0\n",
    "\n",
    "    \n",
    "    adjusted_matrix: np.ndarray = np.matmul(matrix_p, matrix_d)\n",
    "    adjusted_matrix = np.matmul(adjusted_matrix, np.linalg.inv(matrix_p))\n",
    " \n",
    "\n",
    "    #print(f\"Eigenvalues: {np.array2string(test_eigenvalues, precision=4):s}\")\n",
    "    #print(f\"Eigenvectors: {np.array2string(test_eigenvectors, precision=4):s}\")\n",
    "    \n",
    "    #print(f\"Eigenvector matrix: {np.array2string(matrix_p, precision=4):s}\")\n",
    "    #print(f\"Eigenvalue matrix: {np.array2string(matrix_d, precision=4):s}\")\n",
    "    #print(f\"Test matrix: {np.array2string(test_matrix, precision=4):s}\")\n",
    "    #print(f\"Adjusted matrix: {np.array2string(adjusted_matrix, precision=4):s}\")\n",
    "   \n",
    "    \n",
    "    return {'any_errors': False, 'message': '', 'adjusted_matrix': adjusted_matrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b7630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_multivariate_norm(parameters: np.ndarray, num_dimensions: int, variates: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Returns the negative of the log-likelihood function.  The scipy.optimize module only\n",
    "     has a 'minimize' function, so you need to use it to minimize the negative of the\n",
    "     log-likelihood function, which will maximize the positive of the log-likelihood\n",
    "     function.\n",
    "\n",
    "    Expect parameters[0:dimension] to be the mean vector and parameters[dimension:] are the\n",
    "     elements of the lower triangle of the covariance matrix.\n",
    "\n",
    "    Created on August 29 and September 3, 2022\n",
    "    \"\"\"\n",
    "    \n",
    "    function_results: typing.Dict = decode_lh_parameters_norm(parameters, num_dimensions)\n",
    "\n",
    "    mean_vector: np.ndarray = function_results['mean_vector']\n",
    "\n",
    "    cov_matrix: np.ndarray = function_results['covariance_matrix']\n",
    "\n",
    "#    print(f\"Mean vector: {np.array2string(mean_vector, precision=4):s}\")\n",
    "#    print(f\"Covariance matrix: {np.array2string(cov_matrix, precision=4):s}\")\n",
    "    \n",
    "    \n",
    "    # need to ensure that the covariance matrix is positive definite or semi-definite\n",
    "    # first, test it.  if it passes the test, then calculate the likelihood function\n",
    "    # if it fails the test, calculate an adjusted covariance matrix that passes the\n",
    "    #  test and use it to calculate the likelihood function\n",
    "    function_results: typing.Dict = is_matrix_pos_semidef(cov_matrix)\n",
    "\n",
    "    if not function_results['pass_test']:\n",
    "        other_function_results: typing.Dict = trial_pos_semidef_matrix(cov_matrix)\n",
    "        \n",
    "        if other_function_results['any_errors']:\n",
    "            print(other_function_results['message'])\n",
    "            return 0.0\n",
    "        else:\n",
    "            cov_matrix = other_function_results['adjusted_matrix']\n",
    "    \n",
    "    \n",
    "    temp_sum: float = -np.sum(stats.multivariate_normal.logpdf(variates, \n",
    "                                                               mean=mean_vector, \n",
    "                                                               cov=cov_matrix, \n",
    "                                                               allow_singular=False))\n",
    "\n",
    "    print(f\"Log likelihood: {temp_sum:12.6f}\")\n",
    "\n",
    "    return temp_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d5bd0",
   "metadata": {},
   "source": [
    "In order to use the numpy ***minimize*** function, the parameters of the likelihood function need to be fed into the ***minimize*** function as a vector. <br><br>\n",
    "To do this, I set up a ***init_parameters*** one-dimensional NumPy array.  The first part of the array has the elements in the mean vector and the remaining part of the array has the lower triangle of the covariance matrix. <br><br>\n",
    "Suppose you want to estimate the parameters of multi-variate normal distribution with an n-dimensional mean vector and a n-by-n covariance matrix.  The first n elements of the ***init_parameters*** array can store the values of the mean vector. <br><br>\n",
    "You need to ensure that the covariance matrix that's used by the likelihood function is symmetric.  If you simply put every element of the covariance matrix into the ***init_parameters*** array, then there's a good chance that the ***minimize*** function would set elements in the array so that the matrix would no longer be symmetric.  To ensure that this won't happen, I only save the elements of the lower triangle of the covariance matrix in the ***init_parameters*** array.  Inside of the ***log_likelihood_multivariate_norm*** function, I use the remaining elements in the array to set up a symmetric matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875004ce",
   "metadata": {},
   "source": [
    "Here's where I set up the ***init_parameters*** array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9c7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 2\n",
      "Number of parameters in optimization problem: 5\n",
      "[ 2.786  -3.6179  7.021   0.      2.2483]\n"
     ]
    }
   ],
   "source": [
    "num_dimensions: int = random_sample.shape[1]\n",
    "num_elements: int = int(num_dimensions * (num_dimensions + 3) / 2)\n",
    "\n",
    "print(f\"Number of dimensions: {num_dimensions:d}\")\n",
    "print(f\"Number of parameters in optimization problem: {num_elements:d}\")\n",
    "    \n",
    "init_parameters: np.ndarray = np.zeros(num_elements, dtype=np.float32)\n",
    "\n",
    "# set the starting values for the mean vector equal to the sample means.\n",
    "sample_stats = stats.describe(random_sample)\n",
    "\n",
    "for current_element in range(num_dimensions):\n",
    "#    init_parameters[current_element] = 1.0\n",
    "    init_parameters[current_element] = sample_stats[2][current_element]\n",
    "\n",
    "# now set the starting values for the covariance matrix.  set the diagonal\n",
    "#  elements equal to the same variances.\n",
    "current_element:int = num_dimensions\n",
    "for step_size in range(num_dimensions, 0, -1):\n",
    "    if current_element < num_elements:\n",
    "        init_parameters[current_element] = sample_stats[3][num_dimensions - step_size]\n",
    "        current_element += step_size\n",
    "\n",
    "\n",
    "print(np.array2string(init_parameters, precision=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e94601",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally, I run the ***minimize*** function to perform the MLE and obtain the estimated mean vector and covariance matrix.<br><br>\n",
    "\n",
    "\n",
    "You also need to add some boundary conditions for the optimization function.  It's easier to set them up at the same time you set up the ***init_parameters*** array.  The conditions are:\n",
    "* elements on the diagonal in the shape matrix need to be positive.<br><br>\n",
    "\n",
    "You can see from the results that the values in the mean vector and covariance matrix are somewhat close to the values you originally entered.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83a55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: 42173.236657\n",
      "Log likelihood: 42187.055210\n",
      "Log likelihood: 42246.010331\n",
      "Log likelihood: 42179.116054\n",
      "Log likelihood: 42173.812546\n",
      "Log likelihood: 42179.116048\n",
      "Log likelihood: 42248.939185\n",
      "Log likelihood: 42191.663252\n",
      "Log likelihood: 42193.671646\n",
      "Log likelihood: 42178.430791\n",
      "Log likelihood: 42188.724989\n",
      "Log likelihood: 42177.161199\n",
      "Log likelihood: 42182.261889\n",
      "Log likelihood: 42175.210026\n",
      "Log likelihood: 42181.150600\n",
      "Log likelihood: 42175.260321\n",
      "Log likelihood: 42177.321296\n",
      "Log likelihood: 42174.643419\n",
      "Log likelihood: 42176.472272\n",
      "Log likelihood: 42174.365406\n",
      "Log likelihood: 42175.191075\n",
      "Log likelihood: 42175.399972\n",
      "Log likelihood: 42174.073900\n",
      "Log likelihood: 42175.023780\n",
      "Log likelihood: 42173.998559\n",
      "Log likelihood: 42174.532098\n",
      "Log likelihood: 42173.846436\n",
      "Log likelihood: 42173.906075\n",
      "Log likelihood: 42174.082609\n",
      "Log likelihood: 42173.680696\n",
      "Log likelihood: 42174.052178\n",
      "Log likelihood: 42173.651192\n",
      "Log likelihood: 42174.182012\n",
      "Log likelihood: 42173.605151\n",
      "Log likelihood: 42173.823433\n",
      "Log likelihood: 42173.602434\n",
      "Log likelihood: 42173.309232\n",
      "Log likelihood: 42173.379527\n",
      "Log likelihood: 42173.309417\n",
      "Log likelihood: 42173.056890\n",
      "Log likelihood: 42172.888242\n",
      "Log likelihood: 42172.687953\n",
      "Log likelihood: 42172.271004\n",
      "Log likelihood: 42172.572460\n",
      "Log likelihood: 42172.518020\n",
      "Log likelihood: 42172.361806\n",
      "Log likelihood: 42171.684110\n",
      "Log likelihood: 42171.010674\n",
      "Log likelihood: 42171.322033\n",
      "Log likelihood: 42171.295228\n",
      "Log likelihood: 42170.889069\n",
      "Log likelihood: 42170.520951\n",
      "Log likelihood: 42169.949859\n",
      "Log likelihood: 42168.913719\n",
      "Log likelihood: 42168.795257\n",
      "Log likelihood: 42167.426591\n",
      "Log likelihood: 42168.573213\n",
      "Log likelihood: 42167.075115\n",
      "Log likelihood: 42165.436122\n",
      "Log likelihood: 42165.491076\n",
      "Log likelihood: 42163.949999\n",
      "Log likelihood: 42161.757694\n",
      "Log likelihood: 42163.864341\n",
      "Log likelihood: 42160.231525\n",
      "Log likelihood: 42156.465680\n",
      "Log likelihood: 42158.611833\n",
      "Log likelihood: 42158.062789\n",
      "Log likelihood: 42155.735623\n",
      "Log likelihood: 42154.557184\n",
      "Log likelihood: 42151.643230\n",
      "Log likelihood: 42148.261361\n",
      "Log likelihood: 42149.736860\n",
      "Log likelihood: 42149.364116\n",
      "Log likelihood: 42145.318112\n",
      "Log likelihood: 42143.209534\n",
      "Log likelihood: 42154.207868\n",
      "Log likelihood: 42142.409092\n",
      "Log likelihood: 42140.999926\n",
      "Log likelihood: 42142.193460\n",
      "Log likelihood: 42139.080038\n",
      "Log likelihood: 42140.275425\n",
      "Log likelihood: 42133.154099\n",
      "Log likelihood: 42129.123023\n",
      "Log likelihood: 42129.720577\n",
      "Log likelihood: 42128.140071\n",
      "Log likelihood: 42128.519743\n",
      "Log likelihood: 42151.540891\n",
      "Log likelihood: 42133.354742\n",
      "Log likelihood: 42122.346693\n",
      "Log likelihood: 42117.150410\n",
      "Log likelihood: 42113.949617\n",
      "Log likelihood: 42105.354539\n",
      "Log likelihood: 42112.976741\n",
      "Log likelihood: 42114.476149\n",
      "Log likelihood: 42101.159753\n",
      "Log likelihood: 42094.021832\n",
      "Log likelihood: 42090.260562\n",
      "Log likelihood: 42083.457140\n",
      "Log likelihood: 42096.344917\n",
      "Log likelihood: 42073.405740\n",
      "Log likelihood: 42057.899170\n",
      "Log likelihood: 42076.249613\n",
      "Log likelihood: 42080.493428\n",
      "Log likelihood: 42057.205203\n",
      "Log likelihood: 42052.473796\n",
      "Log likelihood: 42058.754653\n",
      "Log likelihood: 42040.671338\n",
      "Log likelihood: 42036.891816\n",
      "Log likelihood: 42012.041575\n",
      "Log likelihood: 41985.166369\n",
      "Log likelihood: 41977.756294\n",
      "Log likelihood: 41936.430936\n",
      "Log likelihood: 41944.729188\n",
      "Log likelihood: 41975.295688\n",
      "Log likelihood: 41914.358498\n",
      "Log likelihood: 41922.235993\n",
      "Log likelihood: 41864.398439\n",
      "Log likelihood: 41827.965367\n",
      "Log likelihood: 41818.901342\n",
      "Log likelihood: 41758.026219\n",
      "Log likelihood: 41800.738900\n",
      "Log likelihood: 41779.975742\n",
      "Log likelihood: 41672.220059\n",
      "Log likelihood: 41617.868714\n",
      "Log likelihood: 41641.570116\n",
      "Log likelihood: 41629.814162\n",
      "Log likelihood: 41663.610373\n",
      "Log likelihood: 41441.699836\n",
      "Log likelihood: 41301.228845\n",
      "Log likelihood: 42211.519271\n",
      "Log likelihood: 41606.298566\n",
      "Log likelihood: 41516.718720\n",
      "Log likelihood: 41422.481809\n",
      "Log likelihood: 41365.489445\n",
      "Log likelihood: 41216.799464\n",
      "Log likelihood: 41058.188503\n",
      "Log likelihood: 40954.956750\n",
      "Log likelihood: 40631.781833\n",
      "Log likelihood: 40755.125667\n",
      "Log likelihood: 40763.333782\n",
      "Log likelihood: 40285.666618\n",
      "Log likelihood: 41045.624020\n",
      "Log likelihood: 39811.392509\n",
      "Log likelihood: 39005.504119\n",
      "Log likelihood: 59718.687339\n",
      "Log likelihood: 40649.285067\n",
      "Log likelihood: 39785.408854\n",
      "Log likelihood: 39263.975057\n",
      "Log likelihood: 39717.935585\n",
      "Log likelihood: 39796.749618\n",
      "Log likelihood: 38396.762046\n",
      "Log likelihood: 46727.500697\n",
      "Log likelihood: 39689.534075\n",
      "Log likelihood: 39255.064425\n",
      "Log likelihood: 38825.683018\n",
      "Log likelihood: 41550.092330\n",
      "Log likelihood: 38969.607003\n",
      "Log likelihood: 42324.749540\n",
      "Log likelihood: 38754.323365\n",
      "Log likelihood: 39485.023396\n",
      "Log likelihood: 38182.002428\n",
      "Log likelihood: 38143.886532\n",
      "Log likelihood: 38294.722831\n",
      "Log likelihood: 37580.387624\n",
      "Log likelihood: 38461.950738\n",
      "Log likelihood: 49189.053924\n",
      "Log likelihood: 38356.465316\n",
      "Log likelihood: 38343.713486\n",
      "Log likelihood: 38288.811351\n",
      "Log likelihood: 37716.409872\n",
      "Log likelihood: 38651.983749\n",
      "Log likelihood: 37570.843076\n",
      "Log likelihood: 41661.934364\n",
      "Log likelihood: 37913.963368\n",
      "Log likelihood: 37346.077961\n",
      "Log likelihood: 37385.233020\n",
      "Log likelihood: 39082.934393\n",
      "Log likelihood: 37746.064220\n",
      "Log likelihood: 37780.037041\n",
      "Log likelihood: 37401.556917\n",
      "Log likelihood: 38432.114761\n",
      "Log likelihood: 37518.347686\n",
      "Log likelihood: 37538.207553\n",
      "Log likelihood: 37502.389856\n",
      "Log likelihood: 37428.163875\n",
      "Log likelihood: 37545.092430\n",
      "Log likelihood: 37425.491683\n",
      "Log likelihood: 37323.761228\n",
      "Log likelihood: 37412.093242\n",
      "Log likelihood: 37191.642439\n",
      "Log likelihood: 37123.876796\n",
      "Log likelihood: 37296.214203\n",
      "Log likelihood: 37121.784582\n",
      "Log likelihood: 37344.492664\n",
      "Log likelihood: 37132.462297\n",
      "Log likelihood: 37006.919014\n",
      "Log likelihood: 37080.813452\n",
      "Log likelihood: 37179.815060\n",
      "Log likelihood: 36857.385643\n",
      "Log likelihood: 36774.532761\n",
      "Log likelihood: 37210.761207\n",
      "Log likelihood: 36990.000802\n",
      "Log likelihood: 37009.446238\n",
      "Log likelihood: 36853.813034\n",
      "Log likelihood: 36757.718878\n",
      "Log likelihood: 36815.395522\n",
      "Log likelihood: 36819.894174\n",
      "Log likelihood: 36607.601060\n",
      "Log likelihood: 36523.810326\n",
      "Log likelihood: 36534.309567\n",
      "Log likelihood: 36857.657674\n",
      "Log likelihood: 36642.755865\n",
      "Log likelihood: 36432.135548\n",
      "Log likelihood: 36314.485074\n",
      "Log likelihood: 36326.186017\n",
      "Log likelihood: 36250.904629\n",
      "Log likelihood: 36211.826138\n",
      "Log likelihood: 36246.279207\n",
      "Log likelihood: 36065.308923\n",
      "Log likelihood: 35971.378984\n",
      "Log likelihood: 35864.599560\n",
      "Log likelihood: 35720.677208\n",
      "Log likelihood: 35952.040557\n",
      "Log likelihood: 35917.396655\n",
      "Log likelihood: 35559.390674\n",
      "Log likelihood: 35336.646659\n",
      "Log likelihood: 35851.251559\n",
      "Log likelihood: 35752.941017\n",
      "Log likelihood: 35499.591480\n",
      "Log likelihood: 35522.384134\n",
      "Log likelihood: 35306.853736\n",
      "Log likelihood: 35429.533339\n",
      "Log likelihood: 35350.907850\n",
      "Log likelihood: 35113.854911\n",
      "Log likelihood: 35071.938995\n",
      "Log likelihood: 35096.021422\n",
      "Log likelihood: 34761.362906\n",
      "Log likelihood: 34640.440106\n",
      "Log likelihood: 35302.421482\n",
      "Log likelihood: 34928.021110\n",
      "Log likelihood: 34591.383445\n",
      "Log likelihood: 34527.845514\n",
      "Log likelihood: 34673.285029\n",
      "Log likelihood: 35044.516896\n",
      "Log likelihood: 38051.781893\n",
      "Log likelihood: 34648.076660\n",
      "Log likelihood: 34984.171370\n",
      "Log likelihood: 34667.383300\n",
      "Log likelihood: 34234.479475\n",
      "Log likelihood: 34360.045281\n",
      "Log likelihood: 34662.220003\n",
      "Log likelihood: 34211.026087\n",
      "Log likelihood: 34158.627700\n",
      "Log likelihood: 34874.463719\n",
      "Log likelihood: 34419.395651\n",
      "Log likelihood: 34177.954276\n",
      "Log likelihood: 34176.144437\n",
      "Log likelihood: 33956.682191\n",
      "Log likelihood: 34255.924950\n",
      "Log likelihood: 34597.559722\n",
      "Log likelihood: 34163.904497\n",
      "Log likelihood: 34217.073771\n",
      "Log likelihood: 34079.078630\n",
      "Log likelihood: 34234.694510\n",
      "Log likelihood: 34057.680825\n",
      "Log likelihood: 34210.001805\n",
      "Log likelihood: 34073.666899\n",
      "Log likelihood: 34122.746131\n",
      "Log likelihood: 33838.863478\n",
      "Log likelihood: 33715.015852\n",
      "Log likelihood: 33977.315347\n",
      "Log likelihood: 33841.347378\n",
      "Log likelihood: 33891.850740\n",
      "Log likelihood: 33760.906184\n",
      "Log likelihood: 33967.262616\n",
      "Log likelihood: 33804.224204\n",
      "Log likelihood: 33651.004312\n",
      "Log likelihood: 33683.684514\n",
      "Log likelihood: 33604.532905\n",
      "Log likelihood: 33584.903836\n",
      "Log likelihood: 33504.711489\n",
      "Log likelihood: 33497.174128\n",
      "Log likelihood: 33407.494733\n",
      "Log likelihood: 33372.000589\n",
      "Log likelihood: 33496.345474\n",
      "Log likelihood: 33225.734586\n",
      "Log likelihood: 33181.831485\n",
      "Log likelihood: 33294.838074\n",
      "Log likelihood: 33322.361649\n",
      "Log likelihood: 33316.659007\n",
      "Log likelihood: 33169.421191\n",
      "Log likelihood: 33375.531846\n",
      "Log likelihood: 33341.802329\n",
      "Log likelihood: 33200.881405\n",
      "Log likelihood: 33236.898080\n",
      "Log likelihood: 33392.063781\n",
      "Log likelihood: 33189.837541\n",
      "Log likelihood: 33246.768656\n",
      "Log likelihood: 33165.150511\n",
      "Log likelihood: 33345.159337\n",
      "Log likelihood: 33162.586160\n",
      "Log likelihood: 33173.268489\n",
      "Log likelihood: 33255.084151\n",
      "Log likelihood: 33147.940617\n",
      "Log likelihood: 33257.001271\n",
      "Log likelihood: 33142.355170\n",
      "Log likelihood: 33198.226172\n",
      "Log likelihood: 33149.512340\n",
      "Log likelihood: 33145.517548\n",
      "Log likelihood: 33184.531117\n",
      "Log likelihood: 33144.420560\n",
      "Log likelihood: 33145.492112\n",
      "Log likelihood: 33131.609879\n",
      "Log likelihood: 33140.872653\n",
      "Log likelihood: 33152.533225\n",
      "Log likelihood: 33136.952880\n",
      "Log likelihood: 33167.772112\n",
      "Log likelihood: 33134.971819\n",
      "Log likelihood: 33148.301801\n",
      "Log likelihood: 33136.246746\n",
      "Log likelihood: 33140.763658\n",
      "Log likelihood: 33136.039426\n",
      "Log likelihood: 33141.875273\n",
      "Log likelihood: 33133.931575\n",
      "Log likelihood: 33131.449500\n",
      "Log likelihood: 33137.397404\n",
      "Log likelihood: 33136.231942\n",
      "Log likelihood: 33132.296892\n",
      "Log likelihood: 33138.037114\n",
      "Log likelihood: 33132.055654\n",
      "Log likelihood: 33136.550682\n",
      "Log likelihood: 33131.815078\n",
      "Log likelihood: 33127.594898\n",
      "Log likelihood: 33125.562316\n",
      "Log likelihood: 33128.325735\n",
      "Log likelihood: 33128.631233\n",
      "Log likelihood: 33126.632030\n",
      "Log likelihood: 33123.952183\n",
      "Log likelihood: 33123.689548\n",
      "Log likelihood: 33122.576177\n",
      "Log likelihood: 33124.927285\n",
      "Log likelihood: 33120.474075\n",
      "Log likelihood: 33120.130647\n",
      "Log likelihood: 33114.960735\n",
      "Log likelihood: 33110.382386\n",
      "Log likelihood: 33121.542684\n",
      "Log likelihood: 33111.996612\n",
      "Log likelihood: 33116.900014\n",
      "Log likelihood: 33119.790144\n",
      "Log likelihood: 33107.170872\n",
      "Log likelihood: 33103.711848\n",
      "Log likelihood: 33101.633487\n",
      "Log likelihood: 33096.990774\n",
      "Log likelihood: 33105.146079\n",
      "Log likelihood: 33095.702677\n",
      "Log likelihood: 33099.513113\n",
      "Log likelihood: 33095.508162\n",
      "Log likelihood: 33103.450473\n",
      "Log likelihood: 33087.332261\n",
      "Log likelihood: 33086.072324\n",
      "Log likelihood: 33086.433395\n",
      "Log likelihood: 33082.570067\n",
      "Log likelihood: 33090.851251\n",
      "Log likelihood: 33089.920370\n",
      "Log likelihood: 33093.994219\n",
      "Log likelihood: 33087.956926\n",
      "Log likelihood: 33085.245843\n",
      "Log likelihood: 33086.022256\n",
      "Log likelihood: 33098.966560\n",
      "Log likelihood: 33081.314241\n",
      "Log likelihood: 33084.352211\n",
      "Log likelihood: 33089.120471\n",
      "Log likelihood: 33081.448362\n",
      "Log likelihood: 33090.372429\n",
      "Log likelihood: 33081.440511\n",
      "Log likelihood: 33090.091435\n",
      "Log likelihood: 33081.006537\n",
      "Log likelihood: 33084.622633\n",
      "Log likelihood: 33081.284450\n",
      "Log likelihood: 33083.024575\n",
      "Log likelihood: 33080.813564\n",
      "Log likelihood: 33081.621685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood: 33080.547916\n",
      "Log likelihood: 33082.143688\n",
      "Log likelihood: 33080.501716\n",
      "Log likelihood: 33082.904002\n",
      "Log likelihood: 33080.389700\n",
      "Log likelihood: 33080.936463\n",
      "Log likelihood: 33082.020513\n",
      "Log likelihood: 33080.340216\n",
      "Log likelihood: 33081.371743\n",
      "Log likelihood: 33080.386844\n",
      "Log likelihood: 33080.582208\n",
      "Log likelihood: 33080.290791\n",
      "Log likelihood: 33080.464960\n",
      "Log likelihood: 33080.347755\n",
      "Log likelihood: 33080.596622\n",
      "Log likelihood: 33080.240590\n",
      "Log likelihood: 33080.908694\n",
      "Log likelihood: 33080.194246\n",
      "Log likelihood: 33080.351494\n",
      "Log likelihood: 33080.224219\n",
      "Log likelihood: 33080.369027\n",
      "Log likelihood: 33080.222633\n",
      "Log likelihood: 33080.448532\n",
      "Log likelihood: 33080.213061\n",
      "Log likelihood: 33080.220840\n",
      "Log likelihood: 33080.271393\n",
      "Log likelihood: 33080.186901\n",
      "Log likelihood: 33080.218429\n",
      "Log likelihood: 33080.205743\n",
      "Log likelihood: 33080.244233\n",
      "Log likelihood: 33080.179504\n",
      "Log likelihood: 33080.184316\n",
      "Log likelihood: 33080.213613\n",
      "Log likelihood: 33080.174810\n",
      "Log likelihood: 33080.227690\n",
      "Log likelihood: 33080.170817\n",
      "Log likelihood: 33080.269308\n",
      "Log likelihood: 33080.164253\n",
      "Log likelihood: 33080.164431\n",
      "Log likelihood: 33080.195413\n",
      "Log likelihood: 33080.164985\n",
      "Log likelihood: 33080.192738\n",
      "Log likelihood: 33080.163601\n",
      "Log likelihood: 33080.166625\n",
      "Log likelihood: 33080.167384\n",
      "Log likelihood: 33080.160063\n",
      "Log likelihood: 33080.172558\n",
      "Log likelihood: 33080.159647\n",
      "Log likelihood: 33080.161716\n",
      "Log likelihood: 33080.167898\n",
      "Log likelihood: 33080.158910\n",
      "Log likelihood: 33080.164264\n",
      "Log likelihood: 33080.159091\n",
      "Log likelihood: 33080.177150\n",
      "Log likelihood: 33080.157861\n",
      "Log likelihood: 33080.163529\n",
      "Log likelihood: 33080.158510\n",
      "Log likelihood: 33080.161077\n",
      "Log likelihood: 33080.158171\n",
      "Log likelihood: 33080.157976\n",
      "Log likelihood: 33080.158700\n",
      "Log likelihood: 33080.157661\n",
      "Log likelihood: 33080.160267\n",
      "Log likelihood: 33080.159620\n",
      "Log likelihood: 33080.157427\n",
      "Log likelihood: 33080.158621\n",
      "Log likelihood: 33080.157440\n",
      "Log likelihood: 33080.159800\n",
      "Log likelihood: 33080.157233\n",
      "Log likelihood: 33080.157862\n",
      "Log likelihood: 33080.157279\n",
      "Log likelihood: 33080.158123\n",
      "Log likelihood: 33080.157259\n",
      "Log likelihood: 33080.158186\n",
      "Log likelihood: 33080.157189\n",
      "Log likelihood: 33080.157265\n",
      "Log likelihood: 33080.157539\n",
      "Log likelihood: 33080.157146\n",
      "Log likelihood: 33080.157235\n",
      "Log likelihood: 33080.157371\n",
      "Log likelihood: 33080.157101\n",
      "Log likelihood: 33080.157213\n",
      "Log likelihood: 33080.157155\n",
      "Log likelihood: 33080.157348\n",
      "Log likelihood: 33080.157076\n",
      "Log likelihood: 33080.157374\n",
      "Log likelihood: 33080.157068\n",
      "Log likelihood: 33080.157285\n",
      "Log likelihood: 33080.157068\n",
      "Log likelihood: 33080.157218\n",
      "Log likelihood: 33080.157063\n",
      "Log likelihood: 33080.157053\n",
      "Log likelihood: 33080.157210\n",
      "Log likelihood: 33080.157270\n",
      "Log likelihood: 33080.157031\n",
      "Log likelihood: 33080.157059\n",
      "Log likelihood: 33080.157024\n",
      "Log likelihood: 33080.157074\n",
      "Log likelihood: 33080.157050\n",
      "Log likelihood: 33080.157062\n",
      "Log likelihood: 33080.157026\n",
      "Log likelihood: 33080.157050\n",
      "Log likelihood: 33080.157037\n",
      "Log likelihood: 33080.157086\n",
      "Log likelihood: 33080.157017\n",
      "Log likelihood: 33080.157062\n",
      "Log likelihood: 33080.157019\n",
      "Log likelihood: 33080.157041\n",
      "Log likelihood: 33080.157017\n",
      "Log likelihood: 33080.157024\n",
      "Log likelihood: 33080.157033\n",
      "Log likelihood: 33080.157013\n",
      "Log likelihood: 33080.157052\n",
      "Log likelihood: 33080.157011\n",
      "Log likelihood: 33080.157032\n",
      "Log likelihood: 33080.157012\n",
      "Log likelihood: 33080.157022\n",
      "Log likelihood: 33080.157012\n",
      "Log likelihood: 33080.157010\n",
      "Log likelihood: 33080.157021\n",
      "Log likelihood: 33080.157020\n",
      "Log likelihood: 33080.157010\n",
      "Log likelihood: 33080.157009\n",
      "Log likelihood: 33080.157017\n",
      "Log likelihood: 33080.157015\n",
      "Log likelihood: 33080.157009\n",
      "Log likelihood: 33080.157008\n",
      "Log likelihood: 33080.157014\n",
      "Log likelihood: 33080.157013\n",
      "Log likelihood: 33080.157008\n",
      "Log likelihood: 33080.157016\n",
      "Log likelihood: 33080.157008\n",
      "Log likelihood: 33080.157009\n",
      "Log likelihood: 33080.157008\n",
      "Estimated mean vector: [ 2.786 -3.618]\n",
      "Estimated covariance matrix: [[ 7.0204 -3.6362]\n",
      " [-3.6362  2.2481]]\n",
      "Optimization terminated successfully.\n",
      "\n",
      "Actual mean vector: [ 2.85 -3.65]\n",
      "Actual covariance matrix: [[ 7.05 -3.65]\n",
      " [-3.65  2.25]]\n"
     ]
    }
   ],
   "source": [
    "boundary_cond: typing.List = []\n",
    "\n",
    "for index, value in enumerate(init_parameters):\n",
    "    if index < num_dimensions:\n",
    "        boundary_cond.append([None,None])\n",
    "    else:\n",
    "        if value == 1:\n",
    "            boundary_cond.append([0,100000])\n",
    "        else:\n",
    "            boundary_cond.append([None,None])\n",
    "\n",
    "\n",
    "opt_results = optimize.minimize(log_likelihood_multivariate_norm, \n",
    "                                x0=init_parameters, \n",
    "                                args=(num_dimensions, random_sample, ), \n",
    "                                method='Nelder-Mead', bounds=boundary_cond,\n",
    "                                options={'maxiter': num_elements * 1000,\n",
    "                                         'maxfev': num_elements * 1000})\n",
    "\n",
    "\n",
    "function_results: typing.Dict = decode_lh_parameters_norm(opt_results['x'], num_dimensions)           \n",
    "\n",
    "print(f\"Estimated mean vector: {np.array2string(function_results['mean_vector'], precision=4):s}\")\n",
    "print(f\"Estimated covariance matrix: {np.array2string(function_results['covariance_matrix'], precision=4):s}\")\n",
    "print(opt_results['message'])\n",
    "\n",
    "print(f\"\\nActual mean vector: {np.array2string(mean_vector, precision=4):s}\")\n",
    "print(f\"Actual covariance matrix: {np.array2string(cov_matrix, precision=4):s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
